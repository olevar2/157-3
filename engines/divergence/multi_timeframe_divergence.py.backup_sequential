# -*- coding: utf-8 -*-
"""
Platform3 Multi-Timeframe Divergence Analyzer
Advanced divergence analysis across multiple timeframes for enhanced signal validation
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from scipy import stats
from scipy.signal import find_peaks
import ta
from dataclasses import dataclass

@dataclass
class TimeframeConfig:
    """Configuration for individual timeframe analysis"""
    name: str
    multiplier: int
    weight: float
    min_bars: int

class MultiTimeframeDivergenceAnalyzer:
    """
    Advanced multi-timeframe divergence analyzer for comprehensive signal validation.
    Analyzes divergences across multiple timeframes and provides consensus scoring.
    """
    
    def __init__(self,
                 base_timeframe: str = '1H',
                 timeframes: Optional[List[TimeframeConfig]] = None,
                 rsi_period: int = 14,
                 macd_fast: int = 12,
                 macd_slow: int = 26,
                 macd_signal: int = 9,
                 stoch_k: int = 14,
                 stoch_d: int = 3,
                 peak_prominence: float = 0.3,
                 min_bars_between_peaks: int = 5,
                 divergence_threshold: float = 0.65,
                 consensus_threshold: float = 0.6):
        """
        Initialize Multi-Timeframe Divergence Analyzer
        
        Parameters:
        -----------
        base_timeframe : str
            Base timeframe for analysis
        timeframes : List[TimeframeConfig]
            Timeframe configurations for analysis
        rsi_period : int
            RSI calculation period
        macd_fast : int
            MACD fast EMA period
        macd_slow : int
            MACD slow EMA period
        macd_signal : int
            MACD signal line period
        stoch_k : int
            Stochastic %K period
        stoch_d : int
            Stochastic %D period
        peak_prominence : float
            Minimum prominence for peak detection
        min_bars_between_peaks : int
            Minimum bars between peaks/troughs
        divergence_threshold : float
            Threshold for individual divergence confirmation
        consensus_threshold : float
            Threshold for multi-timeframe consensus
        """
        self.base_timeframe = base_timeframe
        self.rsi_period = rsi_period
        self.macd_fast = macd_fast
        self.macd_slow = macd_slow
        self.macd_signal = macd_signal
        self.stoch_k = stoch_k
        self.stoch_d = stoch_d
        self.peak_prominence = peak_prominence
        self.min_bars_between_peaks = min_bars_between_peaks
        self.divergence_threshold = divergence_threshold
        self.consensus_threshold = consensus_threshold
        
        # Default timeframe configurations if none provided
        if timeframes is None:
            self.timeframes = [
                TimeframeConfig('Short', 1, 0.15, 50),      # Base timeframe
                TimeframeConfig('Medium', 4, 0.35, 100),    # 4x base (e.g., 4H if base is 1H)
                TimeframeConfig('Long', 24, 0.35, 150),     # 24x base (e.g., 1D if base is 1H)
                TimeframeConfig('Extended', 168, 0.15, 200) # 168x base (e.g., 1W if base is 1H)
            ]
        else:
            self.timeframes = timeframes
        
        # Oscillator weights
        self.oscillator_weights = {
            'rsi': 0.3,
            'macd': 0.4,
            'stochastic': 0.2,
            'momentum': 0.1
        }
    
    def resample_data(self, data: pd.DataFrame, multiplier: int) -> pd.DataFrame:
        """Resample data to higher timeframe"""
        if multiplier == 1:
            return data.copy()
        
        # Create aggregation rules
        agg_rules = {
            'open': 'first',
            'high': 'max',
            'low': 'min',
            'close': 'last',
            'volume': 'sum'
        }
        
        # Resample data
        resampled = data.resample(f'{multiplier}H').agg(agg_rules).dropna()
        
        return resampled
    
    def calculate_oscillators(self, data: pd.DataFrame) -> Dict[str, pd.Series]:
        """Calculate momentum oscillators for divergence analysis"""
        high = data['high']
        low = data['low']
        close = data['close']
        
        oscillators = {}
        
        try:
            # RSI
            oscillators['rsi'] = ta.momentum.RSIIndicator(
                close=close, window=self.rsi_period
            ).rsi()
            
            # MACD
            macd_indicator = ta.trend.MACD(
                close=close,
                window_fast=self.macd_fast,
                window_slow=self.macd_slow,
                window_sign=self.macd_signal
            )
            oscillators['macd'] = macd_indicator.macd()
            
            # Stochastic
            stoch_indicator = ta.momentum.StochasticOscillator(
                high=high, low=low, close=close,
                window=self.stoch_k,
                smooth_window=self.stoch_d
            )
            oscillators['stochastic'] = stoch_indicator.stoch()
            
            # Momentum
            oscillators['momentum'] = ta.momentum.ROCIndicator(
                close=close, window=10
            ).roc()
            
        except Exception as e:
            print(f"Error calculating oscillators: {e}")
            # Return empty series with proper index
            empty_series = pd.Series(index=data.index, dtype=float)
            oscillators = {
                'rsi': empty_series,
                'macd': empty_series,
                'stochastic': empty_series,
                'momentum': empty_series
            }
        
        return oscillators
    
    def detect_peaks_troughs(self, series: pd.Series) -> Tuple[np.ndarray, np.ndarray]:
        """Detect peaks and troughs in a series"""
        clean_series = series.dropna()
        if len(clean_series) < 10:
            return np.array([]), np.array([])
        
        values = clean_series.values
        
        # Find peaks
        peaks, _ = find_peaks(values, 
                             distance=self.min_bars_between_peaks,
                             prominence=self.peak_prominence * np.std(values))
        
        # Find troughs (peaks of inverted series)
        troughs, _ = find_peaks(-values,
                               distance=self.min_bars_between_peaks,
                               prominence=self.peak_prominence * np.std(values))
        
        return peaks, troughs
    
    def calculate_divergence_strength(self, 
                                    price_points: List[float], 
                                    oscillator_points: List[float]) -> float:
        """Calculate divergence strength using slope analysis"""
        if len(price_points) < 2 or len(oscillator_points) < 2:
            return 0.0
        
        try:
            # Calculate normalized slopes
            price_slope = np.polyfit(range(len(price_points)), price_points, 1)[0]
            osc_slope = np.polyfit(range(len(oscillator_points)), oscillator_points, 1)[0]
            
            # Normalize by standard deviation
            price_slope_norm = price_slope / (np.std(price_points) + 1e-8)
            osc_slope_norm = osc_slope / (np.std(oscillator_points) + 1e-8)
            
            # Divergence strength based on opposing slopes
            slope_opposition = abs(np.sign(price_slope_norm) - np.sign(osc_slope_norm)) / 2
            magnitude_factor = min(abs(price_slope_norm) + abs(osc_slope_norm), 2.0) / 2.0
            
            return slope_opposition * magnitude_factor
            
        except (np.linalg.LinAlgError, ValueError):
            return 0.0
    
    def detect_bullish_divergence(self, 
                                price_series: pd.Series, 
                                oscillator_series: pd.Series) -> Dict[str, Any]:
        """Detect bullish divergence (lower price lows, higher oscillator lows)"""
        price_peaks, price_troughs = self.detect_peaks_troughs(price_series)
        osc_peaks, osc_troughs = self.detect_peaks_troughs(oscillator_series)
        
        divergences = []
        
        if len(price_troughs) >= 2 and len(osc_troughs) >= 2:
            # Analyze recent troughs
            for i in range(1, min(len(price_troughs), 4)):
                price_idx1, price_idx2 = price_troughs[-i-1], price_troughs[-i]
                
                # Find corresponding oscillator troughs
                for j in range(len(osc_troughs)-1):
                    osc_idx1, osc_idx2 = osc_troughs[j], osc_troughs[j+1]
                    
                    # Check time alignment
                    if (abs(price_idx1 - osc_idx1) <= 3 and abs(price_idx2 - osc_idx2) <= 3 and
                        price_idx2 > price_idx1 and osc_idx2 > osc_idx1):
                        
                        price_vals = [price_series.iloc[price_idx1], price_series.iloc[price_idx2]]
                        osc_vals = [oscillator_series.iloc[osc_idx1], oscillator_series.iloc[osc_idx2]]
                        
                        # Bullish divergence condition
                        if price_vals[1] < price_vals[0] and osc_vals[1] > osc_vals[0]:
                            strength = self.calculate_divergence_strength(price_vals, osc_vals)
                            
                            if strength >= self.divergence_threshold:
                                divergences.append({
                                    'type': 'bullish',
                                    'strength': strength,
                                    'price_points': (price_idx1, price_idx2),
                                    'oscillator_points': (osc_idx1, osc_idx2),
                                    'price_values': price_vals,
                                    'oscillator_values': osc_vals
                                })
        
        return {
            'divergences': divergences,
            'count': len(divergences),
            'max_strength': max([d['strength'] for d in divergences]) if divergences else 0.0,
            'average_strength': np.mean([d['strength'] for d in divergences]) if divergences else 0.0
        }
    
    def detect_bearish_divergence(self, 
                                price_series: pd.Series, 
                                oscillator_series: pd.Series) -> Dict[str, Any]:
        """Detect bearish divergence (higher price highs, lower oscillator highs)"""
        price_peaks, price_troughs = self.detect_peaks_troughs(price_series)
        osc_peaks, osc_troughs = self.detect_peaks_troughs(oscillator_series)
        
        divergences = []
        
        if len(price_peaks) >= 2 and len(osc_peaks) >= 2:
            # Analyze recent peaks
            for i in range(1, min(len(price_peaks), 4)):
                price_idx1, price_idx2 = price_peaks[-i-1], price_peaks[-i]
                
                # Find corresponding oscillator peaks
                for j in range(len(osc_peaks)-1):
                    osc_idx1, osc_idx2 = osc_peaks[j], osc_peaks[j+1]
                    
                    # Check time alignment
                    if (abs(price_idx1 - osc_idx1) <= 3 and abs(price_idx2 - osc_idx2) <= 3 and
                        price_idx2 > price_idx1 and osc_idx2 > osc_idx1):
                        
                        price_vals = [price_series.iloc[price_idx1], price_series.iloc[price_idx2]]
                        osc_vals = [oscillator_series.iloc[osc_idx1], oscillator_series.iloc[osc_idx2]]
                        
                        # Bearish divergence condition
                        if price_vals[1] > price_vals[0] and osc_vals[1] < osc_vals[0]:
                            strength = self.calculate_divergence_strength(price_vals, osc_vals)
                            
                            if strength >= self.divergence_threshold:
                                divergences.append({
                                    'type': 'bearish',
                                    'strength': strength,
                                    'price_points': (price_idx1, price_idx2),
                                    'oscillator_points': (osc_idx1, osc_idx2),
                                    'price_values': price_vals,
                                    'oscillator_values': osc_vals
                                })
        
        return {
            'divergences': divergences,
            'count': len(divergences),
            'max_strength': max([d['strength'] for d in divergences]) if divergences else 0.0,
            'average_strength': np.mean([d['strength'] for d in divergences]) if divergences else 0.0
        }
    
    def analyze_timeframe_divergences(self, 
                                    data: pd.DataFrame, 
                                    timeframe_config: TimeframeConfig) -> Dict[str, Any]:
        """Analyze divergences for a specific timeframe"""
        # Resample data to target timeframe
        tf_data = self.resample_data(data, timeframe_config.multiplier)
        
        if len(tf_data) < timeframe_config.min_bars:
            return {
                'timeframe': timeframe_config.name,
                'error': 'Insufficient data',
                'required_bars': timeframe_config.min_bars,
                'actual_bars': len(tf_data)
            }
        
        # Calculate oscillators
        oscillators = self.calculate_oscillators(tf_data)
        price_series = tf_data['close']
        
        # Analyze divergences for each oscillator
        oscillator_results = {}
        
        for osc_name, osc_series in oscillators.items():
            if osc_series.dropna().empty:
                continue
            
            bullish_div = self.detect_bullish_divergence(price_series, osc_series)
            bearish_div = self.detect_bearish_divergence(price_series, osc_series)
            
            oscillator_results[osc_name] = {
                'bullish': bullish_div,
                'bearish': bearish_div,
                'total_strength': bullish_div['max_strength'] + bearish_div['max_strength']
            }
        
        # Calculate timeframe scores
        bullish_score = 0.0
        bearish_score = 0.0
        
        for osc_name, weight in self.oscillator_weights.items():
            if osc_name in oscillator_results:
                bullish_score += oscillator_results[osc_name]['bullish']['max_strength'] * weight
                bearish_score += oscillator_results[osc_name]['bearish']['max_strength'] * weight
        
        return {
            'timeframe': timeframe_config.name,
            'multiplier': timeframe_config.multiplier,
            'weight': timeframe_config.weight,
            'data_points': len(tf_data),
            'bullish_score': bullish_score,
            'bearish_score': bearish_score,
            'net_score': bullish_score - bearish_score,
            'oscillator_results': oscillator_results,
            'summary': {
                'total_bullish_divergences': sum(
                    result['bullish']['count'] for result in oscillator_results.values()
                ),
                'total_bearish_divergences': sum(
                    result['bearish']['count'] for result in oscillator_results.values()
                ),
                'strongest_oscillator': max(
                    oscillator_results.keys(),
                    key=lambda x: oscillator_results[x]['total_strength']
                ) if oscillator_results else None
            }
        }
    
    def calculate_multi_timeframe_consensus(self, timeframe_results: List[Dict]) -> Dict[str, Any]:
        """Calculate consensus across all timeframes"""
        bullish_consensus = 0.0
        bearish_consensus = 0.0
        total_weight = 0.0
        
        valid_timeframes = []
        
        for tf_result in timeframe_results:
            if 'error' not in tf_result:
                weight = tf_result['weight']
                bullish_consensus += tf_result['bullish_score'] * weight
                bearish_consensus += tf_result['bearish_score'] * weight
                total_weight += weight
                valid_timeframes.append(tf_result)
        
        # Normalize by total weight
        if total_weight > 0:
            bullish_consensus /= total_weight
            bearish_consensus /= total_weight
        
        net_consensus = bullish_consensus - bearish_consensus
        
        # Determine consensus signal
        if net_consensus > self.consensus_threshold:
            consensus_signal = 'BULLISH_CONSENSUS'
        elif net_consensus < -self.consensus_threshold:
            consensus_signal = 'BEARISH_CONSENSUS'
        else:
            consensus_signal = 'NO_CONSENSUS'
        
        # Calculate confidence based on agreement across timeframes
        timeframe_agreement = 0.0
        if len(valid_timeframes) > 1:
            bullish_signs = sum(1 for tf in valid_timeframes if tf['net_score'] > 0)
            bearish_signs = sum(1 for tf in valid_timeframes if tf['net_score'] < 0)
            total_timeframes = len(valid_timeframes)
            
            timeframe_agreement = max(bullish_signs, bearish_signs) / total_timeframes
        
        confidence = min(abs(net_consensus) * timeframe_agreement * 100, 100)
        
        return {
            'consensus_signal': consensus_signal,
            'bullish_consensus': bullish_consensus,
            'bearish_consensus': bearish_consensus,
            'net_consensus': net_consensus,
            'confidence': confidence,
            'timeframe_agreement': timeframe_agreement,
            'valid_timeframes': len(valid_timeframes),
            'total_timeframes': len(timeframe_results)
        }
    
    def analyze_multi_timeframe_divergences(self, data: pd.DataFrame) -> Dict[str, Any]:
        """
        Comprehensive multi-timeframe divergence analysis
        
        Parameters:
        -----------
        data : pd.DataFrame
            OHLCV data with columns: open, high, low, close, volume
            
        Returns:
        --------
        Dict containing multi-timeframe divergence analysis results
        """
        # Minimum data requirement
        min_required = max(tf.min_bars * tf.multiplier for tf in self.timeframes)
        
        if len(data) < min_required:
            return {
                'error': 'Insufficient data',
                'required_length': min_required,
                'actual_length': len(data)
            }
        
        # Analyze divergences for each timeframe
        timeframe_results = []
        
        for tf_config in self.timeframes:
            tf_result = self.analyze_timeframe_divergences(data, tf_config)
            timeframe_results.append(tf_result)
        
        # Calculate multi-timeframe consensus
        consensus = self.calculate_multi_timeframe_consensus(timeframe_results)
        
        # Aggregate summary statistics
        total_bullish_divs = sum(
            tf.get('summary', {}).get('total_bullish_divergences', 0) 
            for tf in timeframe_results if 'error' not in tf
        )
        total_bearish_divs = sum(
            tf.get('summary', {}).get('total_bearish_divergences', 0) 
            for tf in timeframe_results if 'error' not in tf
        )
        
        return {
            'timestamp': data.index[-1],
            'consensus': consensus,
            'timeframe_results': timeframe_results,
            'summary': {
                'total_bullish_divergences': total_bullish_divs,
                'total_bearish_divergences': total_bearish_divs,
                'net_divergences': total_bullish_divs - total_bearish_divs,
                'timeframes_analyzed': consensus['valid_timeframes'],
                'consensus_strength': abs(consensus['net_consensus'])
            },
            'signal_quality': {
                'high_confidence': consensus['confidence'] > 70,
                'cross_timeframe_agreement': consensus['timeframe_agreement'] > 0.7,
                'strong_consensus': abs(consensus['net_consensus']) > self.consensus_threshold
            }
        }
    
    def get_multi_timeframe_signals(self, data: pd.DataFrame) -> pd.DataFrame:
        """
        Generate multi-timeframe divergence signals as a DataFrame
        
        Returns:
        --------
        pd.DataFrame with multi-timeframe signals
        """
        results = []
        
        # Calculate minimum required data points
        min_required = max(tf.min_bars * tf.multiplier for tf in self.timeframes)
        min_required = max(min_required, 100)  # Absolute minimum
        
        for i in range(min_required, len(data), 5):  # Sample every 5 bars for efficiency
            subset_data = data.iloc[:i+1]
            analysis_result = self.analyze_multi_timeframe_divergences(subset_data)
            
            if 'error' not in analysis_result:
                consensus = analysis_result['consensus']
                results.append({
                    'timestamp': subset_data.index[-1],
                    'consensus_signal': consensus['consensus_signal'],
                    'bullish_consensus': consensus['bullish_consensus'],
                    'bearish_consensus': consensus['bearish_consensus'],
                    'net_consensus': consensus['net_consensus'],
                    'confidence': consensus['confidence'],
                    'timeframe_agreement': consensus['timeframe_agreement'],
                    'total_bullish_divergences': analysis_result['summary']['total_bullish_divergences'],
                    'total_bearish_divergences': analysis_result['summary']['total_bearish_divergences']
                })
            else:
                results.append({
                    'timestamp': subset_data.index[-1],
                    'consensus_signal': 'INSUFFICIENT_DATA',
                    'bullish_consensus': 0.0,
                    'bearish_consensus': 0.0,
                    'net_consensus': 0.0,
                    'confidence': 0.0,
                    'timeframe_agreement': 0.0,
                    'total_bullish_divergences': 0,
                    'total_bearish_divergences': 0
                })
        
        return pd.DataFrame(results).set_index('timestamp')

# Example usage and testing
if __name__ == "__main__":
    # Create sample data
    np.random.seed(42)
    dates = pd.date_range('2023-01-01', periods=500, freq='H')  # Hourly data
    
    # Generate sample OHLCV data with multiple timeframe patterns
    base_trend = np.cumsum(np.random.randn(500) * 0.01)
    noise = np.random.randn(500) * 0.2
    price_base = 100 + base_trend + noise
    
    sample_data = pd.DataFrame({
        'open': price_base * 0.999,
        'high': price_base * 1.002,
        'low': price_base * 0.998,
        'close': price_base,
        'volume': np.random.randint(1000, 10000, 500)
    }, index=dates)
    
    # Test the multi-timeframe divergence analyzer
    analyzer = MultiTimeframeDivergenceAnalyzer()
    
    print("Testing Multi-Timeframe Divergence Analyzer...")
    print("=" * 50)
    
    # Test analysis
    result = analyzer.analyze_multi_timeframe_divergences(sample_data)
    
    if 'error' not in result:
        consensus = result['consensus']
        print(f"Consensus Signal: {consensus['consensus_signal']}")
        print(f"Confidence: {consensus['confidence']:.1f}%")
        print(f"Bullish Consensus: {consensus['bullish_consensus']:.3f}")
        print(f"Bearish Consensus: {consensus['bearish_consensus']:.3f}")
        print(f"Net Consensus: {consensus['net_consensus']:.3f}")
        print(f"Timeframe Agreement: {consensus['timeframe_agreement']:.3f}")
        
        summary = result['summary']
        print(f"\nSummary:")
        print(f"Total Bullish Divergences: {summary['total_bullish_divergences']}")
        print(f"Total Bearish Divergences: {summary['total_bearish_divergences']}")
        print(f"Timeframes Analyzed: {summary['timeframes_analyzed']}")
        print(f"Consensus Strength: {summary['consensus_strength']:.3f}")
        
        # Show timeframe breakdown
        print(f"\nTimeframe Breakdown:")
        for tf_result in result['timeframe_results']:
            if 'error' not in tf_result:
                print(f"{tf_result['timeframe']}: Bullish={tf_result['bullish_score']:.3f}, "
                      f"Bearish={tf_result['bearish_score']:.3f}, "
                      f"Net={tf_result['net_score']:.3f}")
        
        # Test signal generation
        signals_df = analyzer.get_multi_timeframe_signals(sample_data)
        print(f"\nGenerated {len(signals_df)} multi-timeframe signals")
        if not signals_df.empty:
            print(f"Recent signals:\n{signals_df.tail()}")
    else:
        print(f"Error: {result['error']}")
        print(f"Required: {result['required_length']}, Actual: {result['actual_length']}")
