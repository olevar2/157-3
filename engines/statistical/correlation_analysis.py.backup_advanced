"""
Correlation Analysis - Inter-market Correlation Measurement
Essential for risk management and multi-asset trading strategies
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple, Union
from ..indicator_base import IndicatorBase

# Platform3 Winston-style Logging Integration
import sys
import os

# Platform3 Error Handling Integration
from shared.error_handling.platform3_error_system import ServiceError, EventEmitter, CircuitBreaker, ErrorSeverity, ErrorCategory
from shared.error_handling.base_service import BaseService

sys.path.append(os.path.join(os.path.dirname(__file__), '../../shared'))
from logging.platform3_logger import Platform3Logger, log_performance, LogMetadata

class CorrelationAnalysis(IndicatorBase), BaseService:
    """
    Correlation Analysis - Inter-market Correlation Measurement
    
    Analyzes correlation between multiple price series for:
    - Risk management and portfolio diversification
    - Pairs trading opportunities
    - Market regime identification
    - Lead-lag relationship analysis
    - Cross-asset momentum confirmation
    
    Features:
    - Rolling correlation calculation
    - Multiple timeframe analysis
    - Correlation stability assessment
    - Lead-lag analysis
    - Correlation breakdown detection
    """
    
    def __init__(self, 
                 period: int = 20,
                 short_period: int = 5,
                 correlation_threshold: float = 0.7,
                 stability_threshold: float = 0.1):
        """
        Initialize Correlation Analysis
        
        Args:
            period: Main lookback period for correlation calculation
            short_period: Short-term period for trend detection
            correlation_threshold: Threshold for strong correlation classification
            stability_threshold: Threshold for correlation stability
        """
        super().__init__()
        self.period = period
        self.short_period = short_period
        self.correlation_threshold = correlation_threshold
        self.stability_threshold = stability_threshold
        
        # State tracking
        self.price_series = {}
        self.correlations = []
        self.correlation_history = {}
        
    def calculate(self, 
        try:
                 primary_data: Union[pd.DataFrame, Dict],
                 secondary_data: Union[pd.DataFrame, Dict],
                 primary_column: str = 'close',
                 secondary_column: str = 'close',
                 asset_names: Tuple[str, str] = ('Asset1', 'Asset2')) -> Dict:
        """
        Calculate correlation analysis between two price series
        
        Args:
            primary_data: Primary asset price data
            secondary_data: Secondary asset price data
            primary_column: Column name for primary asset prices
            secondary_column: Column name for secondary asset prices
            asset_names: Names for the two assets being compared
            
        Returns:
            Dict containing correlation analysis
        """
        try:
            # Extract price data
            primary_prices = self._extract_prices(primary_data, primary_column)
            secondary_prices = self._extract_prices(secondary_data, secondary_column)
            
            # Align data lengths
            min_length = min(len(primary_prices), len(secondary_prices))
            if min_length < self.period:
                return self._empty_result()
            
            primary_prices = primary_prices[-min_length:]
            secondary_prices = secondary_prices[-min_length:]
            
            # Calculate rolling correlations
            correlations = self._calculate_rolling_correlations(primary_prices, secondary_prices)
            
            # Calculate correlation statistics
            correlation_stats = self._calculate_correlation_statistics(correlations)
            
            # Analyze correlation stability
            stability_analysis = self._analyze_correlation_stability(correlations)
            
            # Detect correlation regimes
            regime_analysis = self._analyze_correlation_regimes(correlations)
            
            # Lead-lag analysis
            lead_lag_analysis = self._analyze_lead_lag_relationship(primary_prices, secondary_prices)
            
            # Generate trading signals
            signals = self._generate_correlation_signals(correlations, primary_prices, secondary_prices)
            
            # Analyze correlation breakdowns
            breakdown_analysis = self._analyze_correlation_breakdowns(correlations)
            
            return {
                'correlations': correlations,
                'current_correlation': correlations[-1] if correlations else 0,
                'correlation_statistics': correlation_stats,
                'stability_analysis': stability_analysis,
                'regime_analysis': regime_analysis,
                'lead_lag_analysis': lead_lag_analysis,
                'signals': signals,
                'breakdown_analysis': breakdown_analysis,
                'asset_names': asset_names,
                'price_relationship': self._analyze_price_relationship(primary_prices, secondary_prices),
                'risk_metrics': self._calculate_risk_metrics(correlations, primary_prices, secondary_prices),
                'period': self.period,
                'threshold': self.correlation_threshold,
                'indicator_name': 'Correlation Analysis'
            }
            
        except Exception as e:
            return {'error': f"Correlation Analysis calculation failed: {str(e)}"}
    
    def calculate_multiple(self, 
        try:
                          data_series: List[Union[pd.DataFrame, Dict]],
                          column_names: List[str] = None,
                          asset_names: List[str] = None) -> Dict:
        """
        Calculate correlation matrix for multiple assets
        
        Args:
            data_series: List of price data for multiple assets
            column_names: List of column names for each asset
            asset_names: List of asset names
            
        Returns:
            Dict containing multi-asset correlation analysis
        """
        try:
            if len(data_series) < 2:
                return {'error': 'At least 2 assets required for correlation analysis'}
            
            if column_names is None:
                column_names = ['close'] * len(data_series)
            
            if asset_names is None:
                asset_names = [f'Asset{i+1}' for i in range(len(data_series))]
            
            # Extract all price series
            price_series = []
            for i, data in enumerate(data_series):
                prices = self._extract_prices(data, column_names[i])
                price_series.append(prices)
            
            # Align all series to same length
            min_length = min(len(prices) for prices in price_series)
            if min_length < self.period:
                return self._empty_result()
            
            aligned_series = [prices[-min_length:] for prices in price_series]
            
            # Calculate correlation matrix
            correlation_matrix = self._calculate_correlation_matrix(aligned_series, asset_names)
            
            # Find strongest correlations
            strongest_correlations = self._find_strongest_correlations(correlation_matrix, asset_names)
            
            # Analyze correlation clusters
            cluster_analysis = self._analyze_correlation_clusters(correlation_matrix, asset_names)
            
            # Portfolio risk analysis
            portfolio_risk = self._calculate_portfolio_risk(aligned_series, correlation_matrix)
            
            return {
                'correlation_matrix': correlation_matrix,
                'strongest_correlations': strongest_correlations,
                'cluster_analysis': cluster_analysis,
                'portfolio_risk': portfolio_risk,
                'asset_names': asset_names,
                'diversification_score': self._calculate_diversification_score(correlation_matrix),
                'indicator_name': 'Multi-Asset Correlation Analysis'
            }
            
        except Exception as e:
            return {'error': f"Multi-asset correlation analysis failed: {str(e)}"}
    
    def _extract_prices(self, data: Union[pd.DataFrame, Dict], column: str) -> List[float]:
        try:
        """Extract price data from various input formats"""
        if isinstance(data, pd.DataFrame):
            return data[column].values.tolist()
        elif isinstance(data, dict):
            return data.get(column, [])
        else:
            return list(data) if hasattr(data, '__iter__') else []
    
    def _calculate_rolling_correlations(self, prices1: List[float], prices2: List[float]) -> List[float]:
        try:
        """Calculate rolling correlation between two price series"""
        correlations = []
        
        for i in range(len(prices1)):
            if i >= self.period - 1:
                # Get windows
                window1 = prices1[max(0, i - self.period + 1):i + 1]
                window2 = prices2[max(0, i - self.period + 1):i + 1]
                
                # Calculate correlation
                correlation = self._calculate_correlation(window1, window2)
                correlations.append(correlation)
            else:
                correlations.append(0.0)
        
        return correlations
    
    def _calculate_correlation(self, series1: List[float], series2: List[float]) -> float:
        try:
        """Calculate correlation coefficient between two series"""
        try:
            if len(series1) != len(series2) or len(series1) < 2:
                return 0.0
            
            # Convert to numpy arrays
            x = np.array(series1)
            y = np.array(series2)
            
            # Calculate correlation
            correlation_matrix = np.corrcoef(x, y)
            correlation = correlation_matrix[0, 1]
            
            # Handle NaN results
            if np.isnan(correlation):
                return 0.0
            
            return float(correlation)
            
        except Exception:
            return 0.0
    
    def _calculate_correlation_statistics(self, correlations: List[float]) -> Dict:
        try:
        """Calculate comprehensive correlation statistics"""
        valid_correlations = [c for c in correlations if not np.isnan(c) and c != 0.0]
        
        if not valid_correlations:
            return {}
        
        current_correlation = correlations[-1] if correlations else 0
        
        return {
            'mean': np.mean(valid_correlations),
            'std': np.std(valid_correlations),
            'min': min(valid_correlations),
            'max': max(valid_correlations),
            'current': current_correlation,
            'median': np.median(valid_correlations),
            'positive_correlation_pct': (len([c for c in valid_correlations if c > 0]) / len(valid_correlations)) * 100,
            'strong_correlation_pct': (len([c for c in valid_correlations if abs(c) > self.correlation_threshold]) / len(valid_correlations)) * 100,
            'current_strength': self._classify_correlation_strength(current_correlation)
        }
    
    def _classify_correlation_strength(self, correlation: float) -> str:
        try:
        """Classify correlation strength"""
        abs_corr = abs(correlation)
        
        if abs_corr >= 0.9:
            return 'VERY_STRONG'
        elif abs_corr >= self.correlation_threshold:
            return 'STRONG'
        elif abs_corr >= 0.5:
            return 'MODERATE'
        elif abs_corr >= 0.3:
            return 'WEAK'
        else:
            return 'VERY_WEAK'
    
    def _analyze_correlation_stability(self, correlations: List[float]) -> Dict:
        try:
        """Analyze correlation stability over time"""
        if len(correlations) < self.period:
            return {}
        
        # Calculate rolling standard deviation of correlations
        stability_window = min(self.period, len(correlations))
        recent_correlations = correlations[-stability_window:]
        
        correlation_std = np.std(recent_correlations)
        stability_score = max(0, 100 - (correlation_std * 100))
        
        # Detect correlation regime changes
        regime_changes = self._detect_regime_changes(correlations)
        
        # Stability classification
        if correlation_std < self.stability_threshold:
            stability_class = 'STABLE'
        elif correlation_std < self.stability_threshold * 2:
            stability_class = 'MODERATELY_STABLE'
        else:
            stability_class = 'UNSTABLE'
        
        return {
            'stability_score': stability_score,
            'correlation_std': correlation_std,
            'stability_class': stability_class,
            'regime_changes': regime_changes,
            'recent_volatility': np.std(correlations[-min(10, len(correlations)):]) if len(correlations) >= 10 else 0
        }
    
    def _detect_regime_changes(self, correlations: List[float]) -> List[Dict]:
        try:
        """Detect significant changes in correlation regimes"""
        regime_changes = []
        
        if len(correlations) < self.period * 2:
            return regime_changes
        
        # Look for significant changes in correlation level
        window_size = self.period // 2
        
        for i in range(window_size, len(correlations) - window_size):
            before_window = correlations[i - window_size:i]
            after_window = correlations[i:i + window_size]
            
            before_mean = np.mean(before_window)
            after_mean = np.mean(after_window)
            
            change_magnitude = abs(after_mean - before_mean)
            
            if change_magnitude > self.stability_threshold * 2:
                regime_changes.append({
                    'index': i,
                    'before_correlation': before_mean,
                    'after_correlation': after_mean,
                    'change_magnitude': change_magnitude,
                    'change_type': 'INCREASE' if after_mean > before_mean else 'DECREASE'
                })
        
        return regime_changes[-5:]  # Return last 5 regime changes
    
    def _analyze_correlation_regimes(self, correlations: List[float]) -> Dict:
        try:
        """Analyze different correlation regimes"""
        if not correlations:
            return {}
        
        # Classify current regime
        current_correlation = correlations[-1]
        
        if current_correlation > self.correlation_threshold:
            current_regime = 'HIGH_POSITIVE'
        elif current_correlation < -self.correlation_threshold:
            current_regime = 'HIGH_NEGATIVE'
        elif current_correlation > 0.3:
            current_regime = 'MODERATE_POSITIVE'
        elif current_correlation < -0.3:
            current_regime = 'MODERATE_NEGATIVE'
        else:
            current_regime = 'LOW_CORRELATION'
        
        # Analyze regime persistence
        regime_persistence = self._calculate_regime_persistence(correlations)
        
        # Historical regime distribution
        regime_distribution = self._calculate_regime_distribution(correlations)
        
        return {
            'current_regime': current_regime,
            'regime_persistence': regime_persistence,
            'regime_distribution': regime_distribution,
            'regime_strength': abs(current_correlation)
        }
    
    def _calculate_regime_persistence(self, correlations: List[float]) -> Dict:
        try:
        """Calculate how long current regime has persisted"""
        if not correlations:
            return {}
        
        current_correlation = correlations[-1]
        current_regime = self._classify_correlation_strength(current_correlation)
        
        # Count consecutive periods in current regime
        persistence_count = 1
        for i in range(len(correlations) - 2, -1, -1):
            if self._classify_correlation_strength(correlations[i]) == current_regime:
                persistence_count += 1
            else:
                break
        
        return {
            'current_regime': current_regime,
            'persistence_periods': persistence_count,
            'persistence_score': min(100, persistence_count * 5)
        }
    
    def _calculate_regime_distribution(self, correlations: List[float]) -> Dict:
        try:
        """Calculate distribution of correlation regimes"""
        regime_counts = {
            'VERY_STRONG': 0,
            'STRONG': 0,
            'MODERATE': 0,
            'WEAK': 0,
            'VERY_WEAK': 0
        }
        
        for correlation in correlations:
            strength = self._classify_correlation_strength(correlation)
            if strength in regime_counts:
                regime_counts[strength] += 1
        
        total = len(correlations)
        regime_percentages = {k: (v / total * 100) if total > 0 else 0 for k, v in regime_counts.items()}
        
        return regime_percentages
    
    def _analyze_lead_lag_relationship(self, prices1: List[float], prices2: List[float]) -> Dict:
        try:
        """Analyze lead-lag relationship between two price series"""
        if len(prices1) < self.period or len(prices2) < self.period:
            return {}
        
        # Test different lag periods
        max_lag = min(5, self.period // 4)
        lag_correlations = {}
        
        for lag in range(-max_lag, max_lag + 1):
            if lag == 0:
                corr = self._calculate_correlation(prices1, prices2)
            elif lag > 0:
                # prices1 leads prices2
                if len(prices1) > lag and len(prices2) > lag:
                    corr = self._calculate_correlation(prices1[:-lag], prices2[lag:])
                else:
                    corr = 0
            else:
                # prices2 leads prices1
                abs_lag = abs(lag)
                if len(prices1) > abs_lag and len(prices2) > abs_lag:
                    corr = self._calculate_correlation(prices1[abs_lag:], prices2[:-abs_lag])
                else:
                    corr = 0
            
            lag_correlations[lag] = corr
        
        # Find optimal lag
        best_lag = max(lag_correlations.keys(), key=lambda k: abs(lag_correlations[k]))
        best_correlation = lag_correlations[best_lag]
        
        # Interpret results
        if best_lag > 0:
            lead_lag_relationship = f"Asset1 leads Asset2 by {best_lag} periods"
        elif best_lag < 0:
            lead_lag_relationship = f"Asset2 leads Asset1 by {abs(best_lag)} periods"
        else:
            lead_lag_relationship = "No clear lead-lag relationship"
        
        return {
            'lag_correlations': lag_correlations,
            'optimal_lag': best_lag,
            'optimal_correlation': best_correlation,
            'relationship': lead_lag_relationship,
            'lead_lag_strength': abs(best_correlation) - abs(lag_correlations.get(0, 0))
        }
    
    def _generate_correlation_signals(self, correlations: List[float], 
        try:
                                    prices1: List[float], prices2: List[float]) -> Dict:
        """Generate trading signals based on correlation analysis"""
        if len(correlations) < 2:
            return {'action': 'HOLD', 'strength': 0, 'confidence': 0}
        
        current_correlation = correlations[-1]
        prev_correlation = correlations[-2]
        correlation_change = current_correlation - prev_correlation
        
        # Signal generation
        action = 'HOLD'
        strength = 0
        confidence = 0
        signal_type = 'CORRELATION'
        
        # Correlation breakdown signals (pairs trading opportunities)
        if abs(current_correlation) > self.correlation_threshold:
            # Check for price divergence despite high correlation
            price1_change = (prices1[-1] - prices1[-self.short_period]) / prices1[-self.short_period] * 100
            price2_change = (prices2[-1] - prices2[-self.short_period]) / prices2[-self.short_period] * 100
            
            price_divergence = abs(price1_change - price2_change)
            
            if price_divergence > 2.0:  # Significant divergence
                if price1_change > price2_change:
                    action = 'PAIRS_TRADE'
                    strength = min(100, int(price_divergence * 10))
                    confidence = min(90, int(abs(current_correlation) * 80))
                    signal_type = 'MEAN_REVERSION_PAIRS'
                else:
                    action = 'PAIRS_TRADE_REVERSE'
                    strength = min(100, int(price_divergence * 10))
                    confidence = min(90, int(abs(current_correlation) * 80))
                    signal_type = 'MEAN_REVERSION_PAIRS'
        
        # Correlation trend signals
        if abs(correlation_change) > self.stability_threshold:
            if correlation_change > 0 and current_correlation > 0:
                signal_type = 'CORRELATION_STRENGTHENING'
            elif correlation_change < 0:
                signal_type = 'CORRELATION_WEAKENING'
        
        return {
            'action': action,
            'strength': strength,
            'confidence': confidence,
            'signal_type': signal_type,
            'current_correlation': current_correlation,
            'correlation_change': correlation_change,
            'correlation_strength': self._classify_correlation_strength(current_correlation)
        }
    
    def _analyze_correlation_breakdowns(self, correlations: List[float]) -> Dict:
        try:
        """Analyze correlation breakdown events"""
        breakdowns = []
        
        if len(correlations) < self.period:
            return {'breakdowns': [], 'recent_count': 0}
        
        # Look for significant correlation drops
        for i in range(self.period, len(correlations)):
            current_corr = correlations[i]
            avg_prev_corr = np.mean(correlations[i - self.period:i])
            
            # Detect breakdown (significant drop in correlation)
            if abs(avg_prev_corr) > self.correlation_threshold and abs(current_corr) < abs(avg_prev_corr) - 0.3:
                breakdowns.append({
                    'index': i,
                    'before_correlation': avg_prev_corr,
                    'after_correlation': current_corr,
                    'breakdown_magnitude': abs(avg_prev_corr) - abs(current_corr),
                    'severity': 'HIGH' if abs(avg_prev_corr) - abs(current_corr) > 0.5 else 'MODERATE'
                })
        
        recent_count = len([b for b in breakdowns if len(correlations) - b['index'] <= 20])
        
        return {
            'breakdowns': breakdowns[-3:],  # Last 3 breakdowns
            'recent_count': recent_count,
            'total_breakdowns': len(breakdowns),
            'avg_breakdown_magnitude': np.mean([b['breakdown_magnitude'] for b in breakdowns]) if breakdowns else 0
        }
    
    def _analyze_price_relationship(self, prices1: List[float], prices2: List[float]) -> Dict:
        try:
        """Analyze the relationship between price levels and movements"""
        if len(prices1) < 2 or len(prices2) < 2:
            return {}
        
        # Price level correlation
        price_correlation = self._calculate_correlation(prices1, prices2)
        
        # Returns correlation
        returns1 = [(prices1[i] - prices1[i-1]) / prices1[i-1] for i in range(1, len(prices1))]
        returns2 = [(prices2[i] - prices2[i-1]) / prices2[i-1] for i in range(1, len(prices2))]
        returns_correlation = self._calculate_correlation(returns1, returns2)
        
        # Volatility correlation
        volatility1 = [abs(r) for r in returns1]
        volatility2 = [abs(r) for r in returns2]
        volatility_correlation = self._calculate_correlation(volatility1, volatility2)
        
        return {
            'price_correlation': price_correlation,
            'returns_correlation': returns_correlation,
            'volatility_correlation': volatility_correlation,
            'relationship_type': self._classify_relationship_type(price_correlation, returns_correlation)
        }
    
    def _classify_relationship_type(self, price_corr: float, returns_corr: float) -> str:
        try:
        """Classify the type of relationship between assets"""
        if abs(price_corr) > 0.8 and abs(returns_corr) > 0.8:
            return 'STRONG_COINTEGRATED'
        elif abs(price_corr) > 0.6 and abs(returns_corr) > 0.6:
            return 'MODERATE_COINTEGRATED'
        elif abs(returns_corr) > 0.6:
            return 'RETURNS_CORRELATED'
        elif abs(price_corr) > 0.6:
            return 'PRICE_CORRELATED'
        else:
            return 'WEAK_RELATIONSHIP'
    
    def _calculate_risk_metrics(self, correlations: List[float], 
        try:
                               prices1: List[float], prices2: List[float]) -> Dict:
        """Calculate risk metrics based on correlation"""
        if not correlations or len(prices1) < 2 or len(prices2) < 2:
            return {}
        
        current_correlation = correlations[-1]
        
        # Portfolio variance calculation (assuming equal weights)
        returns1 = [(prices1[i] - prices1[i-1]) / prices1[i-1] for i in range(1, len(prices1))]
        returns2 = [(prices2[i] - prices2[i-1]) / prices2[i-1] for i in range(1, len(prices2))]
        
        var1 = np.var(returns1) if returns1 else 0
        var2 = np.var(returns2) if returns2 else 0
        
        # Portfolio variance with correlation
        portfolio_variance = 0.25 * var1 + 0.25 * var2 + 0.5 * current_correlation * np.sqrt(var1 * var2)
        portfolio_volatility = np.sqrt(portfolio_variance)
        
        # Diversification benefit
        avg_individual_volatility = (np.sqrt(var1) + np.sqrt(var2)) / 2
        diversification_benefit = (avg_individual_volatility - portfolio_volatility) / avg_individual_volatility * 100
        
        return {
            'portfolio_volatility': portfolio_volatility,
            'diversification_benefit': diversification_benefit,
            'correlation_risk': abs(current_correlation) * 100,
            'risk_level': 'HIGH' if abs(current_correlation) > 0.8 else 'MEDIUM' if abs(current_correlation) > 0.5 else 'LOW'
        }
    
    def _calculate_correlation_matrix(self, price_series: List[List[float]], asset_names: List[str]) -> Dict:
        try:
        """Calculate correlation matrix for multiple assets"""
        n_assets = len(price_series)
        correlation_matrix = {}
        
        for i in range(n_assets):
            correlation_matrix[asset_names[i]] = {}
            for j in range(n_assets):
                if i == j:
                    correlation_matrix[asset_names[i]][asset_names[j]] = 1.0
                else:
                    corr = self._calculate_correlation(price_series[i], price_series[j])
                    correlation_matrix[asset_names[i]][asset_names[j]] = corr
        
        return correlation_matrix
    
    def _find_strongest_correlations(self, correlation_matrix: Dict, asset_names: List[str]) -> List[Dict]:
        try:
        """Find strongest correlations in the matrix"""
        correlations = []
        
        for i, asset1 in enumerate(asset_names):
            for j, asset2 in enumerate(asset_names):
                if i < j:  # Avoid duplicates
                    corr = correlation_matrix[asset1][asset2]
                    correlations.append({
                        'asset1': asset1,
                        'asset2': asset2,
                        'correlation': corr,
                        'strength': self._classify_correlation_strength(corr)
                    })
        
        # Sort by absolute correlation
        correlations.sort(key=lambda x: abs(x['correlation']), reverse=True)
        return correlations[:5]  # Top 5 strongest correlations
    
    def _analyze_correlation_clusters(self, correlation_matrix: Dict, asset_names: List[str]) -> Dict:
        try:
        """Analyze correlation clusters among assets"""
        high_corr_pairs = []
        clusters = []
        
        # Find highly correlated pairs
        for asset1 in asset_names:
            for asset2 in asset_names:
                if asset1 != asset2:
                    corr = correlation_matrix[asset1][asset2]
                    if abs(corr) > self.correlation_threshold:
                        high_corr_pairs.append((asset1, asset2, corr))
        
        # Simple clustering (assets with multiple high correlations)
        cluster_candidates = {}
        for asset1, asset2, corr in high_corr_pairs:
            if asset1 not in cluster_candidates:
                cluster_candidates[asset1] = []
            if asset2 not in cluster_candidates:
                cluster_candidates[asset2] = []
            
            cluster_candidates[asset1].append(asset2)
            cluster_candidates[asset2].append(asset1)
        
        # Form clusters
        processed = set()
        for asset, connected in cluster_candidates.items():
            if asset not in processed and len(connected) >= 1:
                cluster = {asset}
                cluster.update(connected)
                clusters.append(list(cluster))
                processed.update(cluster)
        
        return {
            'high_correlation_pairs': len(high_corr_pairs),
            'clusters': clusters[:3],  # Top 3 clusters
            'clustered_assets': len(processed),
            'cluster_strength': len(high_corr_pairs) / len(asset_names) if asset_names else 0
        }
    
    def _calculate_portfolio_risk(self, price_series: List[List[float]], correlation_matrix: Dict) -> Dict:
        try:
        """Calculate portfolio-wide risk metrics"""
        n_assets = len(price_series)
        
        # Calculate individual volatilities
        volatilities = []
        for prices in price_series:
            if len(prices) > 1:
                returns = [(prices[i] - prices[i-1]) / prices[i-1] for i in range(1, len(prices))]
                volatilities.append(np.std(returns))
            else:
                volatilities.append(0)
        
        # Equal weight portfolio variance
        equal_weight = 1.0 / n_assets
        portfolio_variance = 0
        
        asset_names = list(correlation_matrix.keys())
        
        for i in range(n_assets):
            for j in range(n_assets):
                if i < len(asset_names) and j < len(asset_names):
                    corr = correlation_matrix[asset_names[i]][asset_names[j]]
                    portfolio_variance += equal_weight * equal_weight * volatilities[i] * volatilities[j] * corr
        
        portfolio_volatility = np.sqrt(portfolio_variance)
        avg_individual_volatility = np.mean(volatilities)
        diversification_ratio = avg_individual_volatility / portfolio_volatility if portfolio_volatility > 0 else 1
        
        return {
            'portfolio_volatility': portfolio_volatility,
            'average_individual_volatility': avg_individual_volatility,
            'diversification_ratio': diversification_ratio,
            'diversification_benefit': (diversification_ratio - 1) * 100
        }
    
    def _calculate_diversification_score(self, correlation_matrix: Dict) -> float:
        try:
        """Calculate overall diversification score"""
        asset_names = list(correlation_matrix.keys())
        n_assets = len(asset_names)
        
        if n_assets < 2:
            return 0
        
        # Average absolute correlation
        total_correlation = 0
        pair_count = 0
        
        for i in range(n_assets):
            for j in range(i + 1, n_assets):
                total_correlation += abs(correlation_matrix[asset_names[i]][asset_names[j]])
                pair_count += 1
        
        avg_correlation = total_correlation / pair_count if pair_count > 0 else 0
        
        # Diversification score (lower correlation = higher score)
        diversification_score = max(0, 100 - (avg_correlation * 100))
        
        return diversification_score
    
    def _empty_result(self) -> Dict:
        try:
        """Return empty result when insufficient data"""
        return {
            'correlations': [],
            'signals': {},
            'statistics': {},
            'indicator_name': 'Correlation Analysis',
            'error': 'Insufficient data for calculation'
        }

    def generate_signal(self):
        try:
        """Generate correlation-based signal"""
        from ..indicator_base import IndicatorSignal, SignalType
        
        if not hasattr(self, '_last_result') or not self._last_result:
            return IndicatorSignal(
                signal_type=SignalType.NEUTRAL,
                strength=0.0,
                confidence=0.0,
                message="No correlation data available"
            )
        
        # Extract correlation statistics
        stats = self._last_result.get('statistics', {})
        current_correlation = stats.get('current_correlation', 0.0)
        correlation_stability = stats.get('correlation_stability', 0.0)
        
        # Determine signal based on correlation strength and stability
        if abs(current_correlation) > self.correlation_threshold and correlation_stability > 0.7:
            signal_type = SignalType.STRONG_BUY if current_correlation > 0 else SignalType.STRONG_SELL
            strength = min(1.0, abs(current_correlation))
            confidence = correlation_stability
            message = f"Strong correlation detected: {current_correlation:.3f}"
        elif abs(current_correlation) > 0.5:
            signal_type = SignalType.BUY if current_correlation > 0 else SignalType.SELL
            strength = abs(current_correlation) * 0.7
            confidence = correlation_stability * 0.8
            message = f"Moderate correlation: {current_correlation:.3f}"
        else:
            signal_type = SignalType.NEUTRAL
            strength = 0.3
            confidence = 0.5
            message = f"Weak correlation: {current_correlation:.3f}"
        
        return IndicatorSignal(
            signal_type=signal_type,
            strength=strength,
            confidence=confidence,
            message=message
        )


    def handle_service_error(self, error: Exception, context: Dict[str, Any] = None) -> None:
        """Handle service errors with proper event emission and logging"""
        try:
            service_error = ServiceError(
                message=str(error),
                code=f"{self.__class__.__name__.upper()}_ERROR",
                metadata={
                    "file_path": "engines/statistical/correlation_analysis.py",
                    "context": context or {},
                    "timestamp": pd.Timestamp.now().isoformat(),
                    "service_name": self.__class__.__name__
                }
            )
            
            # Emit error event for monitoring
            self.emit('error', service_error)
            
            # Log error with correlation context
            if hasattr(self, 'logger'):
                self.logger.error(f"Service error in {self.__class__.__name__}: {str(error)}", extra={
                        "error_code": service_error.code,
                        "error_severity": service_error.severity.value,
                        "error_category": service_error.category.value,
                        "context": context
                    })
        except Exception as handling_error:
            # Fallback error handling
            print(f"Critical error in error handling: {handling_error}")
    
    def implement_circuit_breaker(self, service_name: str, failure_threshold: int = 5) -> CircuitBreaker:
        """Implement circuit breaker for external service calls"""
        return CircuitBreaker(
            service_name=service_name,
            failure_threshold=failure_threshold,
            recovery_timeout=30,
            on_failure=lambda error: self.emit('circuit_breaker_open', {'service': service_name, 'error': error})
        )
    
    def graceful_degradation(self, primary_function, fallback_function, context: str = "operation"):
        """Implement graceful degradation pattern"""
        try:
            return primary_function()
        except Exception as error:
            self.handle_service_error(error, {"context": context, "degradation": "fallback_used"})
            
            # Emit degradation event
            self.emit('service_degradation', {
                'context': context,
                'primary_error': str(error),
                'fallback_activated': True
            })
            
            return fallback_function()

def calculate_correlation(primary_data: Union[pd.DataFrame, Dict],
                         secondary_data: Union[pd.DataFrame, Dict],
                         period: int = 20,
                         primary_column: str = 'close',
                         secondary_column: str = 'close',
                         asset_names: Tuple[str, str] = ('Asset1', 'Asset2')) -> Dict:
    """
    Convenience function for correlation analysis
    
    Args:
        primary_data: Primary asset price data
        secondary_data: Secondary asset price data
        period: Lookback period
        primary_column: Primary asset price column
        secondary_column: Secondary asset price column
        asset_names: Names of the assets
        
    Returns:
        Correlation analysis results
    """
    analyzer = CorrelationAnalysis(period)
    return analyzer.calculate(primary_data, secondary_data, primary_column, secondary_column, asset_names)
