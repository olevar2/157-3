"""
Platform3 Market Regime Detection
Advanced market regime identification using multiple statistical and technical approaches
"""

import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any, Union
from scipy import stats
from scipy.cluster import hierarchy
from sklearn.mixture import GaussianMixture
from sklearn.preprocessing import StandardScaler
import ta
import warnings

# Platform3 Error Handling Integration
from shared.error_handling.platform3_error_system import ServiceError, EventEmitter, CircuitBreaker, ErrorSeverity, ErrorCategory
from shared.error_handling.base_service import BaseService

warnings.filterwarnings('ignore')

class MarketRegimeDetector, BaseService:
    """
    Advanced market regime detector using multiple methodologies:
    - Hidden Markov Models (HMM) approximation
    - Gaussian Mixture Models (GMM)
    - Volatility regime detection
    - Trend regime analysis
    - Volume regime classification
    """
    
    def __init__(self,
                 lookback_period: int = 252,
                 short_ma: int = 20,
                 long_ma: int = 50,
                 volatility_window: int = 20,
                 volume_window: int = 30,
                 n_regimes: int = 3,
                 confidence_threshold: float = 0.7,
                 regime_persistence: int = 5):
        """
        Initialize Market Regime Detector
        
        Parameters:
        -----------
        lookback_period : int
            Lookback period for regime analysis
        short_ma : int
            Short moving average period
        long_ma : int
            Long moving average period
        volatility_window : int
            Window for volatility calculation
        volume_window : int
            Window for volume analysis
        n_regimes : int
            Number of regimes to detect (typically 3: bull, bear, sideways)
        confidence_threshold : float
            Minimum confidence for regime classification
        regime_persistence : int
            Minimum periods for regime persistence
        """
        self.lookback_period = lookback_period
        self.short_ma = short_ma
        self.long_ma = long_ma
        self.volatility_window = volatility_window
        self.volume_window = volume_window
        self.n_regimes = n_regimes
        self.confidence_threshold = confidence_threshold
        self.regime_persistence = regime_persistence
        
        # Regime definitions
        self.regime_names = {
            0: 'BULL_MARKET',
            1: 'BEAR_MARKET', 
            2: 'SIDEWAYS_MARKET'
        }
        
        # Feature weights for regime classification
        self.feature_weights = {
            'trend_strength': 0.25,
            'volatility_regime': 0.20,
            'momentum': 0.20,
            'volume_profile': 0.15,
            'price_momentum': 0.20
        }
    
    def calculate_market_features(self, data: pd.DataFrame) -> pd.DataFrame:
        try:
        """
        Calculate comprehensive market features for regime detection
        
        Parameters:
        -----------
        data : pd.DataFrame
            OHLCV data
            
        Returns:
        --------
        pd.DataFrame with calculated features
        """
        df = data.copy()
        
        # Price-based features
        df['returns'] = df['close'].pct_change()
        df['log_returns'] = np.log(df['close'] / df['close'].shift(1))
        
        # Moving averages
        df['sma_short'] = df['close'].rolling(window=self.short_ma).mean()
        df['sma_long'] = df['close'].rolling(window=self.long_ma).mean()
        df['ema_short'] = df['close'].ewm(span=self.short_ma).mean()
        df['ema_long'] = df['close'].ewm(span=self.long_ma).mean()
        
        # Trend features
        df['ma_ratio'] = df['sma_short'] / df['sma_long']
        df['price_vs_ma_short'] = df['close'] / df['sma_short']
        df['price_vs_ma_long'] = df['close'] / df['sma_long']
        
        # Trend strength (slope of price)
        df['trend_strength'] = df['close'].rolling(window=20).apply(
            lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) == 20 else np.nan
        )
        
        # Volatility features
        df['volatility'] = df['returns'].rolling(window=self.volatility_window).std()
        df['volatility_percentile'] = df['volatility'].rolling(window=60).rank(pct=True)
        
        # Calculate ATR
        try:
            df['atr'] = ta.volatility.AverageTrueRange(
                high=df['high'], low=df['low'], close=df['close'],
                window=14
            ).average_true_range()
        except:
            df['atr'] = df['volatility'] * df['close']
        
        # Momentum indicators
        try:
            # RSI
            df['rsi'] = ta.momentum.RSIIndicator(
                close=df['close'], window=14
            ).rsi()
            
            # MACD
            macd = ta.trend.MACD(close=df['close'])
            df['macd'] = macd.macd()
            df['macd_signal'] = macd.macd_signal()
            df['macd_histogram'] = macd.macd_diff()
            
            # Stochastic
            stoch = ta.momentum.StochasticOscillator(
                high=df['high'], low=df['low'], close=df['close']
            )
            df['stoch_k'] = stoch.stoch()
            
        except:
            # Fallback calculations
            df['rsi'] = 50.0
            df['macd'] = 0.0
            df['macd_signal'] = 0.0
            df['macd_histogram'] = 0.0
            df['stoch_k'] = 50.0
        
        # Volume features
        if 'volume' in df.columns:
            df['volume_ma'] = df['volume'].rolling(window=self.volume_window).mean()
            df['volume_ratio'] = df['volume'] / df['volume_ma']
            df['volume_trend'] = df['volume'].rolling(window=10).apply(
                lambda x: np.polyfit(range(len(x)), x, 1)[0] if len(x) == 10 else np.nan
            )
        else:
            df['volume_ma'] = 1.0
            df['volume_ratio'] = 1.0
            df['volume_trend'] = 0.0
        
        # Higher highs and lower lows
        df['higher_high'] = (df['high'] > df['high'].shift(1)).astype(int)
        df['lower_low'] = (df['low'] < df['low'].shift(1)).astype(int)
        
        # Rolling max and min for support/resistance
        df['rolling_max'] = df['high'].rolling(window=20).max()
        df['rolling_min'] = df['low'].rolling(window=20).min()
        df['price_position'] = (df['close'] - df['rolling_min']) / (df['rolling_max'] - df['rolling_min'])
        
        return df
    
    def detect_volatility_regimes(self, data: pd.DataFrame) -> pd.Series:
        try:
        """
        Detect volatility regimes using Gaussian Mixture Models
        
        Parameters:
        -----------
        data : pd.DataFrame
            Data with volatility features
            
        Returns:
        --------
        pd.Series with volatility regime classifications
        """
        volatility = data['volatility'].dropna()
        
        if len(volatility) < 30:
            return pd.Series(index=data.index, data=1)  # Default to medium volatility
        
        # Prepare data for clustering
        vol_features = np.column_stack([
            volatility.values,
            data['atr'].dropna().reindex(volatility.index).fillna(method='ffill').values,
        ])
        
        # Standardize features
        scaler = StandardScaler()
        vol_features_scaled = scaler.fit_transform(vol_features)
        
        # Fit Gaussian Mixture Model
        try:
            gmm = GaussianMixture(n_components=3, random_state=42)
            vol_regimes = gmm.fit_predict(vol_features_scaled)
            
            # Map regimes to meaningful labels (0: low, 1: medium, 2: high)
            regime_means = []
            for i in range(3):
                regime_mask = vol_regimes == i
                if np.sum(regime_mask) > 0:
                    regime_means.append(np.mean(volatility.values[regime_mask]))
                else:
                    regime_means.append(0)
            
            # Sort regimes by volatility level
            regime_order = np.argsort(regime_means)
            regime_mapping = {regime_order[i]: i for i in range(3)}
            vol_regimes_mapped = np.array([regime_mapping[r] for r in vol_regimes])
            
            # Create full series
            vol_regime_series = pd.Series(index=data.index, data=1)  # Default medium
            vol_regime_series.loc[volatility.index] = vol_regimes_mapped
            
            return vol_regime_series
            
        except Exception as e:
            # Fallback to percentile-based classification
            vol_regime_series = pd.Series(index=data.index, data=1)
            vol_percentiles = volatility.rolling(window=60).rank(pct=True)
            
            vol_regime_series.loc[vol_percentiles.index] = np.where(
                vol_percentiles < 0.33, 0,  # Low volatility
                np.where(vol_percentiles > 0.67, 2, 1)  # High volatility, else medium
            )
            
            return vol_regime_series
    
    def detect_trend_regimes(self, data: pd.DataFrame) -> pd.Series:
        try:
        """
        Detect trend regimes based on multiple trend indicators
        
        Parameters:
        -----------
        data : pd.DataFrame
            Data with trend features
            
        Returns:
        --------
        pd.Series with trend regime classifications
        """
        # Combine multiple trend indicators
        trend_indicators = []
        
        # MA crossover signal
        ma_signal = np.where(data['ma_ratio'] > 1.02, 1,  # Bullish
                           np.where(data['ma_ratio'] < 0.98, -1, 0))  # Bearish, else neutral
        trend_indicators.append(ma_signal)
        
        # Price vs MA signal
        price_ma_signal = np.where(data['price_vs_ma_long'] > 1.05, 1,
                                 np.where(data['price_vs_ma_long'] < 0.95, -1, 0))
        trend_indicators.append(price_ma_signal)
        
        # Trend strength signal
        trend_strength_norm = data['trend_strength'] / data['close'] * 252  # Annualized
        strength_signal = np.where(trend_strength_norm > 0.1, 1,
                                 np.where(trend_strength_norm < -0.1, -1, 0))
        trend_indicators.append(strength_signal)
        
        # MACD signal
        macd_signal = np.where(data['macd'] > data['macd_signal'], 1,
                             np.where(data['macd'] < data['macd_signal'], -1, 0))
        trend_indicators.append(macd_signal)
        
        # Combine signals
        trend_score = np.mean(trend_indicators, axis=0)
        
        # Map to regime (0: bear, 1: sideways, 2: bull)
        trend_regime = np.where(trend_score > 0.3, 2,  # Bull
                              np.where(trend_score < -0.3, 0, 1))  # Bear, else sideways
        
        return pd.Series(index=data.index, data=trend_regime)
    
    def detect_momentum_regimes(self, data: pd.DataFrame) -> pd.Series:
        try:
        """
        Detect momentum regimes using oscillator analysis
        
        Parameters:
        -----------
        data : pd.DataFrame
            Data with momentum features
            
        Returns:
        --------
        pd.Series with momentum regime classifications
        """
        momentum_scores = []
        
        # RSI-based momentum
        rsi_momentum = np.where(data['rsi'] > 55, 1,
                              np.where(data['rsi'] < 45, -1, 0))
        momentum_scores.append(rsi_momentum)
        
        # Stochastic momentum
        stoch_momentum = np.where(data['stoch_k'] > 55, 1,
                                np.where(data['stoch_k'] < 45, -1, 0))
        momentum_scores.append(stoch_momentum)
        
        # Price momentum (rate of change)
        price_roc = data['close'].pct_change(periods=10)
        roc_momentum = np.where(price_roc > 0.02, 1,
                              np.where(price_roc < -0.02, -1, 0))
        momentum_scores.append(roc_momentum)
        
        # Combine momentum scores
        momentum_score = np.mean(momentum_scores, axis=0)
        
        # Map to regime
        momentum_regime = np.where(momentum_score > 0.2, 2,  # Bullish momentum
                                 np.where(momentum_score < -0.2, 0, 1))  # Bearish, else neutral
        
        return pd.Series(index=data.index, data=momentum_regime)
    
    def detect_volume_regimes(self, data: pd.DataFrame) -> pd.Series:
        try:
        """
        Detect volume regimes for market participation analysis
        
        Parameters:
        -----------
        data : pd.DataFrame
            Data with volume features
            
        Returns:
        --------
        pd.Series with volume regime classifications
        """
        if 'volume' not in data.columns:
            return pd.Series(index=data.index, data=1)  # Default neutral
        
        # Volume trend analysis
        volume_trend_signal = np.where(data['volume_trend'] > 0, 1,
                                     np.where(data['volume_trend'] < 0, -1, 0))
        
        # Volume ratio analysis
        volume_ratio_signal = np.where(data['volume_ratio'] > 1.2, 1,
                                     np.where(data['volume_ratio'] < 0.8, -1, 0))
        
        # Combine volume signals
        volume_score = (volume_trend_signal + volume_ratio_signal) / 2
        
        # Map to regime (0: low participation, 1: normal, 2: high participation)
        volume_regime = np.where(volume_score > 0.3, 2,
                               np.where(volume_score < -0.3, 0, 1))
        
        return pd.Series(index=data.index, data=volume_regime)
    
    def calculate_regime_consensus(self, 
        try:
                                 trend_regimes: pd.Series,
                                 volatility_regimes: pd.Series,
                                 momentum_regimes: pd.Series,
                                 volume_regimes: pd.Series) -> pd.DataFrame:
        """
        Calculate consensus regime using weighted combination
        
        Parameters:
        -----------
        trend_regimes : pd.Series
            Trend regime classifications
        volatility_regimes : pd.Series
            Volatility regime classifications
        momentum_regimes : pd.Series
            Momentum regime classifications
        volume_regimes : pd.Series
            Volume regime classifications
            
        Returns:
        --------
        pd.DataFrame with consensus regime analysis
        """
        # Create feature matrix for regime classification
        regime_features = pd.DataFrame({
            'trend': trend_regimes,
            'volatility': volatility_regimes,
            'momentum': momentum_regimes,
            'volume': volume_regimes
        })
        
        # Calculate weighted regime scores
        bull_score = (
            self.feature_weights['trend_strength'] * (regime_features['trend'] == 2).astype(int) +
            self.feature_weights['volatility_regime'] * (regime_features['volatility'] == 0).astype(int) +  # Low vol favors bull
            self.feature_weights['momentum'] * (regime_features['momentum'] == 2).astype(int) +
            self.feature_weights['volume_profile'] * (regime_features['volume'] == 2).astype(int)
        )
        
        bear_score = (
            self.feature_weights['trend_strength'] * (regime_features['trend'] == 0).astype(int) +
            self.feature_weights['volatility_regime'] * (regime_features['volatility'] == 2).astype(int) +  # High vol can indicate bear
            self.feature_weights['momentum'] * (regime_features['momentum'] == 0).astype(int) +
            self.feature_weights['volume_profile'] * (regime_features['volume'] == 0).astype(int)
        )
        
        sideways_score = (
            self.feature_weights['trend_strength'] * (regime_features['trend'] == 1).astype(int) +
            self.feature_weights['volatility_regime'] * (regime_features['volatility'] == 1).astype(int) +
            self.feature_weights['momentum'] * (regime_features['momentum'] == 1).astype(int) +
            self.feature_weights['volume_profile'] * (regime_features['volume'] == 1).astype(int)
        )
        
        # Determine consensus regime
        regime_scores = pd.DataFrame({
            'bull_score': bull_score,
            'bear_score': bear_score,
            'sideways_score': sideways_score
        })
        
        # Find regime with highest score
        consensus_regime = regime_scores.idxmax(axis=1).map({
            'bull_score': 2,
            'bear_score': 0,
            'sideways_score': 1
        })
        
        # Calculate confidence as the difference between top two scores
        sorted_scores = regime_scores.apply(lambda x: x.sort_values(ascending=False), axis=1)
        confidence = (sorted_scores.iloc[:, 0] - sorted_scores.iloc[:, 1]) / sorted_scores.iloc[:, 0]
        confidence = confidence.fillna(0)
        
        return pd.DataFrame({
            'consensus_regime': consensus_regime,
            'confidence': confidence,
            'bull_score': bull_score,
            'bear_score': bear_score,
            'sideways_score': sideways_score,
            'trend_regime': trend_regimes,
            'volatility_regime': volatility_regimes,
            'momentum_regime': momentum_regimes,
            'volume_regime': volume_regimes
        })
    
    def apply_regime_persistence(self, regimes: pd.Series, confidence: pd.Series) -> pd.Series:
        try:
        """
        Apply regime persistence filter to reduce noise
        
        Parameters:
        -----------
        regimes : pd.Series
            Raw regime classifications
        confidence : pd.Series
            Confidence scores
            
        Returns:
        --------
        pd.Series with smoothed regimes
        """
        smoothed_regimes = regimes.copy()
        
        for i in range(self.regime_persistence, len(regimes)):
            # Look at recent window
            recent_regimes = regimes.iloc[i-self.regime_persistence:i+1]
            recent_confidence = confidence.iloc[i-self.regime_persistence:i+1]
            
            # If confidence is low, use most common recent regime
            if confidence.iloc[i] < self.confidence_threshold:
                # Weight by confidence
                weighted_regimes = []
                for j, (regime, conf) in enumerate(zip(recent_regimes, recent_confidence)):
                    weighted_regimes.extend([regime] * max(1, int(conf * 5)))
                
                if weighted_regimes:
                    smoothed_regimes.iloc[i] = max(set(weighted_regimes), key=weighted_regimes.count)
        
        return smoothed_regimes
    
    def detect_market_regimes(self, data: pd.DataFrame) -> Dict[str, Any]:
        try:
        """
        Comprehensive market regime detection
        
        Parameters:
        -----------
        data : pd.DataFrame
            OHLCV data
            
        Returns:
        --------
        Dict containing comprehensive regime analysis
        """
        if len(data) < max(self.lookback_period // 2, 100):
            return {
                'error': 'Insufficient data',
                'required_length': max(self.lookback_period // 2, 100),
                'actual_length': len(data)
            }
        
        # Calculate market features
        feature_data = self.calculate_market_features(data)
        
        # Detect individual regime components
        trend_regimes = self.detect_trend_regimes(feature_data)
        volatility_regimes = self.detect_volatility_regimes(feature_data)
        momentum_regimes = self.detect_momentum_regimes(feature_data)
        volume_regimes = self.detect_volume_regimes(feature_data)
        
        # Calculate consensus regime
        consensus_analysis = self.calculate_regime_consensus(
            trend_regimes, volatility_regimes, momentum_regimes, volume_regimes
        )
        
        # Apply persistence filtering
        smoothed_regime = self.apply_regime_persistence(
            consensus_analysis['consensus_regime'], 
            consensus_analysis['confidence']
        )
        
        # Current regime analysis
        current_regime = smoothed_regime.iloc[-1]
        current_confidence = consensus_analysis['confidence'].iloc[-1]
        current_regime_name = self.regime_names[current_regime]
        
        # Regime stability analysis
        recent_regimes = smoothed_regime.tail(20)
        regime_stability = (recent_regimes == current_regime).mean()
        
        # Regime duration
        regime_changes = (smoothed_regime != smoothed_regime.shift(1)).cumsum()
        current_regime_start = regime_changes[regime_changes == regime_changes.iloc[-1]].index[0]
        regime_duration = len(data.loc[current_regime_start:])
        
        # Regime transition probabilities (simple estimation)
        regime_transitions = pd.crosstab(smoothed_regime.shift(1), smoothed_regime, normalize='index')
        
        return {
            'timestamp': data.index[-1],
            'current_regime': current_regime_name,
            'regime_code': current_regime,
            'confidence': current_confidence,
            'stability': regime_stability,
            'duration': regime_duration,
            'component_regimes': {
                'trend': self.regime_names[trend_regimes.iloc[-1]],
                'volatility': ['LOW', 'MEDIUM', 'HIGH'][volatility_regimes.iloc[-1]],
                'momentum': self.regime_names[momentum_regimes.iloc[-1]],
                'volume': ['LOW', 'NORMAL', 'HIGH'][volume_regimes.iloc[-1]]
            },
            'regime_scores': {
                'bull_score': consensus_analysis['bull_score'].iloc[-1],
                'bear_score': consensus_analysis['bear_score'].iloc[-1],
                'sideways_score': consensus_analysis['sideways_score'].iloc[-1]
            },
            'transition_probabilities': regime_transitions.to_dict() if not regime_transitions.empty else {},
            'regime_history': {
                'consensus_regimes': smoothed_regime.tail(30).to_dict(),
                'confidence_history': consensus_analysis['confidence'].tail(30).to_dict()
            },
            'summary': {
                'regime_quality': 'High' if current_confidence > 0.7 else 'Medium' if current_confidence > 0.4 else 'Low',
                'regime_persistence': 'Stable' if regime_stability > 0.8 else 'Moderate' if regime_stability > 0.6 else 'Unstable',
                'market_state': current_regime_name,
                'trading_environment': self._get_trading_environment(current_regime, volatility_regimes.iloc[-1])
            }
        }
    
    def _get_trading_environment(self, regime: int, volatility: int) -> str:
        try:
        """Get trading environment description"""
        if regime == 2:  # Bull
            if volatility == 0:
                return 'BULLISH_LOW_VOL'
            elif volatility == 1:
                return 'BULLISH_NORMAL_VOL'
            else:
                return 'BULLISH_HIGH_VOL'
        elif regime == 0:  # Bear
            if volatility == 0:
                return 'BEARISH_LOW_VOL'
            elif volatility == 1:
                return 'BEARISH_NORMAL_VOL'
            else:
                return 'BEARISH_HIGH_VOL'
        else:  # Sideways
            if volatility == 0:
                return 'SIDEWAYS_LOW_VOL'
            elif volatility == 1:
                return 'SIDEWAYS_NORMAL_VOL'
            else:
                return 'SIDEWAYS_HIGH_VOL'
    
    def get_regime_signals(self, data: pd.DataFrame) -> pd.DataFrame:
        try:
        """
        Generate regime detection signals as a DataFrame
        
        Parameters:
        -----------
        data : pd.DataFrame
            OHLCV data
            
        Returns:
        --------
        pd.DataFrame with regime signals
        """
        results = []
        
        # Minimum required data
        min_required = max(self.lookback_period // 3, 80)
        
        for i in range(min_required, len(data), 5):  # Sample every 5 periods for efficiency
            subset_data = data.iloc[:i+1]
            regime_result = self.detect_market_regimes(subset_data)
            
            if 'error' not in regime_result:
                results.append({
                    'timestamp': subset_data.index[-1],
                    'regime': regime_result['current_regime'],
                    'regime_code': regime_result['regime_code'],
                    'confidence': regime_result['confidence'],
                    'stability': regime_result['stability'],
                    'duration': regime_result['duration'],
                    'bull_score': regime_result['regime_scores']['bull_score'],
                    'bear_score': regime_result['regime_scores']['bear_score'],
                    'sideways_score': regime_result['regime_scores']['sideways_score'],
                    'trading_environment': regime_result['summary']['trading_environment'],
                    'regime_quality': regime_result['summary']['regime_quality']
                })
            else:
                results.append({
                    'timestamp': subset_data.index[-1],
                    'regime': 'UNKNOWN',
                    'regime_code': -1,
                    'confidence': 0.0,
                    'stability': 0.0,
                    'duration': 0,
                    'bull_score': 0.0,
                    'bear_score': 0.0,
                    'sideways_score': 0.0,
                    'trading_environment': 'UNKNOWN',
                    'regime_quality': 'None'
                })
        
        return pd.DataFrame(results).set_index('timestamp')


    def handle_service_error(self, error: Exception, context: Dict[str, Any] = None) -> None:
        """Handle service errors with proper event emission and logging"""
        try:
            service_error = ServiceError(
                message=str(error),
                code=f"{self.__class__.__name__.upper()}_ERROR",
                metadata={
                    "file_path": "engines/cycle/market_regime_detection.py",
                    "context": context or {},
                    "timestamp": pd.Timestamp.now().isoformat(),
                    "service_name": self.__class__.__name__
                }
            )
            
            # Emit error event for monitoring
            self.emit('error', service_error)
            
            # Log error with correlation context
            if hasattr(self, 'logger'):
                self.logger.error(
                    f"Service error in {self.__class__.__name__}: {str(error)}",
                    extra={
                        "error_code": service_error.code,
                        "error_severity": service_error.severity.value,
                        "error_category": service_error.category.value,
                        "context": context
                    }
                )
        except Exception as handling_error:
            # Fallback error handling
            print(f"Critical error in error handling: {handling_error}")
    
    def implement_circuit_breaker(self, service_name: str, failure_threshold: int = 5) -> CircuitBreaker:
        """Implement circuit breaker for external service calls"""
        return CircuitBreaker(
            service_name=service_name,
            failure_threshold=failure_threshold,
            recovery_timeout=30,
            on_failure=lambda error: self.emit('circuit_breaker_open', {'service': service_name, 'error': error})
        )
    
    def graceful_degradation(self, primary_function, fallback_function, context: str = "operation"):
        """Implement graceful degradation pattern"""
        try:
            return primary_function()
        except Exception as error:
            self.handle_service_error(error, {"context": context, "degradation": "fallback_used"})
            
            # Emit degradation event
            self.emit('service_degradation', {
                'context': context,
                'primary_error': str(error),
                'fallback_activated': True
            })
            
            return fallback_function()

# Example usage and testing
if __name__ == "__main__":
    # Create sample data with different market regimes
    np.random.seed(42)
    dates = pd.date_range('2023-01-01', periods=400, freq='D')
    
    # Generate sample data with regime changes
    bull_period = np.cumsum(np.random.randn(120) * 0.01 + 0.002)  # Bull market
    bear_period = np.cumsum(np.random.randn(120) * 0.015 - 0.003)  # Bear market
    sideways_period = np.cumsum(np.random.randn(160) * 0.008)  # Sideways
    
    price_changes = np.concatenate([bull_period, bear_period, sideways_period])
    price_base = 100 + price_changes
    
    # Add volatility variations
    volatility = np.concatenate([
        np.random.randn(120) * 0.5,  # Low vol bull
        np.random.randn(120) * 1.2,  # High vol bear
        np.random.randn(160) * 0.8   # Medium vol sideways
    ])
    
    sample_data = pd.DataFrame({
        'open': price_base * (1 + volatility * 0.002),
        'high': price_base * (1 + np.abs(volatility) * 0.003),
        'low': price_base * (1 - np.abs(volatility) * 0.003),
        'close': price_base * (1 + volatility * 0.002),
        'volume': np.random.randint(1000, 10000, 400)
    }, index=dates)
    
    # Test the market regime detector
    detector = MarketRegimeDetector(lookback_period=200)
    
    print("Testing Market Regime Detector...")
    print("=" * 50)
    
    # Test detection
    result = detector.detect_market_regimes(sample_data)
    
    if 'error' not in result:
        print(f"Current Regime: {result['current_regime']}")
        print(f"Confidence: {result['confidence']:.3f}")
        print(f"Stability: {result['stability']:.3f}")
        print(f"Duration: {result['duration']} periods")
        
        component_regimes = result['component_regimes']
        print(f"\nComponent Regimes:")
        print(f"Trend: {component_regimes['trend']}")
        print(f"Volatility: {component_regimes['volatility']}")
        print(f"Momentum: {component_regimes['momentum']}")
        print(f"Volume: {component_regimes['volume']}")
        
        regime_scores = result['regime_scores']
        print(f"\nRegime Scores:")
        print(f"Bull Score: {regime_scores['bull_score']:.3f}")
        print(f"Bear Score: {regime_scores['bear_score']:.3f}")
        print(f"Sideways Score: {regime_scores['sideways_score']:.3f}")
        
        summary = result['summary']
        print(f"\nSummary:")
        print(f"Regime Quality: {summary['regime_quality']}")
        print(f"Regime Persistence: {summary['regime_persistence']}")
        print(f"Market State: {summary['market_state']}")
        print(f"Trading Environment: {summary['trading_environment']}")
        
        # Test signal generation
        signals_df = detector.get_regime_signals(sample_data)
        print(f"\nGenerated {len(signals_df)} regime signals")
        if not signals_df.empty:
            print(f"Recent signals:\n{signals_df.tail()}")
        
    else:
        print(f"Error: {result['error']}")
        print(f"Required: {result['required_length']}, Actual: {result['actual_length']}")
