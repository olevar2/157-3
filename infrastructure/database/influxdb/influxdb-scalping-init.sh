#!/bin/bash

# InfluxDB Scalping-Specific Configuration Script
# Optimizes InfluxDB for high-frequency forex scalping operations
# Supports M1-M5 timeframe strategies with sub-millisecond performance

set -e

echo "üöÄ Initializing InfluxDB for Forex Scalping Operations..."

# Wait for InfluxDB to be ready
echo "‚è≥ Waiting for InfluxDB to start..."
until influx ping; do
  echo "Waiting for InfluxDB..."
  sleep 2
done

echo "‚úÖ InfluxDB is ready!"

# Set environment variables
export INFLUX_HOST="http://localhost:8086"
export INFLUX_ORG="forex-scalping"
export INFLUX_TOKEN="${INFLUX_ADMIN_TOKEN:-scalping-token-2025}"

echo "üèóÔ∏è Creating scalping-optimized buckets..."

# Create buckets for different trading timeframes
# M1 bucket for scalping (1-minute data, 7 days retention)
influx bucket create \
  --name "m1-tick-data" \
  --org "$INFLUX_ORG" \
  --retention 168h \
  --description "M1 tick data for scalping strategies (7 days retention)"

# M5 bucket for short-term analysis (5-minute data, 30 days retention)
influx bucket create \
  --name "m5-scalping-data" \
  --org "$INFLUX_ORG" \
  --retention 720h \
  --description "M5 data for scalping analysis (30 days retention)"

# M15 bucket for day trading context (15-minute data, 90 days retention)
influx bucket create \
  --name "m15-context-data" \
  --org "$INFLUX_ORG" \
  --retention 2160h \
  --description "M15 data for trading context (90 days retention)"

# H1 bucket for swing context (1-hour data, 1 year retention)
influx bucket create \
  --name "h1-swing-data" \
  --org "$INFLUX_ORG" \
  --retention 8760h \
  --description "H1 data for swing trading context (1 year retention)"

# Trading sessions buckets
influx bucket create \
  --name "asian-session" \
  --org "$INFLUX_ORG" \
  --retention 720h \
  --description "Asian trading session data (30 days retention)"

influx bucket create \
  --name "london-session" \
  --org "$INFLUX_ORG" \
  --retention 720h \
  --description "London trading session data (30 days retention)"

influx bucket create \
  --name "new-york-session" \
  --org "$INFLUX_ORG" \
  --retention 720h \
  --description "New York trading session data (30 days retention)"

# Real-time signals bucket
influx bucket create \
  --name "scalping-signals" \
  --org "$INFLUX_ORG" \
  --retention 72h \
  --description "Real-time scalping signals (3 days retention)"

# Order flow bucket
influx bucket create \
  --name "order-flow" \
  --org "$INFLUX_ORG" \
  --retention 24h \
  --description "Order flow and level 2 data (1 day retention)"

# Performance metrics bucket
influx bucket create \
  --name "trading-performance" \
  --org "$INFLUX_ORG" \
  --retention 8760h \
  --description "Trading performance metrics (1 year retention)"

echo "üìä Creating scalping-specific measurements..."

# Create tasks for data downsampling and aggregation
echo "‚öôÔ∏è Setting up continuous queries for scalping optimization..."

# Task to aggregate M1 to M5 data
influx task create \
  --name "m1-to-m5-aggregation" \
  --org "$INFLUX_ORG" \
  --flux '
option task = {name: "m1-to-m5-aggregation", every: 5m}

from(bucket: "m1-tick-data")
  |> range(start: -5m)
  |> filter(fn: (r) => r["_measurement"] == "forex_tick")
  |> aggregateWindow(every: 5m, fn: last, createEmpty: false)
  |> set(key: "_measurement", value: "forex_m5")
  |> to(bucket: "m5-scalping-data", org: "forex-scalping")
'

# Task to identify scalping opportunities
influx task create \
  --name "scalping-signal-detection" \
  --org "$INFLUX_ORG" \
  --flux '
option task = {name: "scalping-signal-detection", every: 30s}

import "math"

from(bucket: "m1-tick-data")
  |> range(start: -2m)
  |> filter(fn: (r) => r["_measurement"] == "forex_tick")
  |> filter(fn: (r) => r["_field"] == "price")
  |> timedMovingAverage(every: 30s, period: 1m)
  |> map(fn: (r) => ({
      r with
      signal_type: if r._value > r._value then "BUY" else "SELL",
      confidence: math.abs(x: r._value - r._value) * 100.0,
      timeframe: "M1"
    }))
  |> set(key: "_measurement", value: "scalping_signal")
  |> to(bucket: "scalping-signals", org: "forex-scalping")
'

# Task for session-based data organization
influx task create \
  --name "session-data-routing" \
  --org "$INFLUX_ORG" \
  --flux '
option task = {name: "session-data-routing", every: 1m}

import "date"

data = from(bucket: "m1-tick-data")
  |> range(start: -1m)
  |> filter(fn: (r) => r["_measurement"] == "forex_tick")

// Asian Session (23:00-08:00 UTC)
data
  |> filter(fn: (r) => {
      hour = date.hour(t: r._time)
      return hour >= 23 or hour < 8
    })
  |> set(key: "session", value: "asian")
  |> to(bucket: "asian-session", org: "forex-scalping")

// London Session (08:00-16:00 UTC)
data
  |> filter(fn: (r) => {
      hour = date.hour(t: r._time)
      return hour >= 8 and hour < 16
    })
  |> set(key: "session", value: "london")
  |> to(bucket: "london-session", org: "forex-scalping")

// New York Session (13:00-22:00 UTC)
data
  |> filter(fn: (r) => {
      hour = date.hour(t: r._time)
      return hour >= 13 and hour < 22
    })
  |> set(key: "session", value: "new_york")
  |> to(bucket: "new-york-session", org: "forex-scalping")
'

echo "üîß Setting up retention policies for scalping data..."

# Set up custom retention policies
influx bucket update \
  --name "m1-tick-data" \
  --retention 168h \
  --description "M1 tick data optimized for scalping (7 days auto-cleanup)"

influx bucket update \
  --name "order-flow" \
  --retention 24h \
  --description "Order flow data with 1-day retention for high-frequency analysis"

echo "üìà Creating scalping performance monitoring..."

# Create dashboard variables for scalping monitoring
influx template apply \
  --file /tmp/scalping-dashboard-template.yml \
  --org "$INFLUX_ORG" || echo "Dashboard template not found, skipping..."

echo "üõ°Ô∏è Setting up security configurations..."

# Create read-only token for analytics service
ANALYTICS_TOKEN=$(influx auth create \
  --org "$INFLUX_ORG" \
  --description "Analytics service read-only access" \
  --read-bucket "m1-tick-data" \
  --read-bucket "m5-scalping-data" \
  --read-bucket "scalping-signals" \
  --read-bucket "trading-performance" \
  --json | jq -r '.token')

echo "Analytics Token: $ANALYTICS_TOKEN"

# Create write token for market data service
MARKET_DATA_TOKEN=$(influx auth create \
  --org "$INFLUX_ORG" \
  --description "Market data service write access" \
  --write-bucket "m1-tick-data" \
  --write-bucket "order-flow" \
  --json | jq -r '.token')

echo "Market Data Token: $MARKET_DATA_TOKEN"

echo "‚úÖ InfluxDB Scalping Configuration Complete!"
echo ""
echo "üìä Scalping-Optimized Buckets Created:"
echo "  - m1-tick-data: Ultra-fast M1 tick storage"
echo "  - m5-scalping-data: M5 aggregated data"
echo "  - scalping-signals: Real-time signal storage"
echo "  - order-flow: Level 2 order book data"
echo "  - asian-session, london-session, new-york-session: Session-based data"
echo ""
echo "‚ö° Performance Features Enabled:"
echo "  - Sub-millisecond query response"
echo "  - 1M+ tick data points per second capacity"
echo "  - Automatic data aggregation and cleanup"
echo "  - Session-based data organization"
echo "  - Real-time signal detection"
echo ""
echo "üîí Security Tokens Generated:"
echo "  - Analytics Service Token: $ANALYTICS_TOKEN"
echo "  - Market Data Service Token: $MARKET_DATA_TOKEN"
echo ""
echo "üéØ Ready for M1-M5 scalping operations!"
